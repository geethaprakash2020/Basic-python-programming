{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist sequential study pranalis class 24th jan,30th jan 2021",
      "provenance": [],
      "authorship_tag": "ABX9TyPNDcDBQoSxzvLBA6r221A3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geethaprakash2020/Basic-python-programming/blob/master/Mnist_sequential_study_pranalis_class_24th_jan%2C30th_jan_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRwt9fE_QT3Y"
      },
      "source": [
        "<p><h2><b><font color = 'Blue'> MNIST Case Study </font></b></h2></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QmhIZ93QbEj"
      },
      "source": [
        "The MNIST problem is a dataset developed by Yann LeCun, Corinna Cortes and Christopher Burges for evaluating machine learning models on the handwritten digit classification problem.\r\n",
        "\r\n",
        "The dataset was constructed from a number of scanned document dataset available from the National Institute of Standards and Technology (NIST). This is where the name for the dataset comes from, as the Modified NIST or MNIST dataset.\r\n",
        "\r\n",
        "Images of digits were taken from a variety of scanned documents, normalized in size and centered. This makes it an excellent dataset for evaluating models, allowing the developer to focus on the machine learning with very little data cleaning or preparation required.\r\n",
        "\r\n",
        "Each image is a 28 by 28 pixel square (784 pixels total). A standard split of the dataset is used to evaluate and compare models, where 60,000 images are used to train a model and a separate set of 10,000 images are used to test it.\r\n",
        "\r\n",
        "It is a digit recognition task. As such there are 10 digits (0 to 9) or 10 classes to predict. Results are reported using prediction error, which is nothing more than the inverted classification accuracy.\r\n",
        "\r\n",
        "<img src = 'https://dim-mlp-images.s3.amazonaws.com/Deep+Learning/MINST/MNIST.png'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBGZlXYPHOa9"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiJevXWgHV7F"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a_shPoxmHWCq",
        "outputId": "fa600f0d-3163-43b6-d687-8c093bc79705"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-oRb-71EHWK0",
        "outputId": "dedf609d-9e30-4a39-e95b-ddac8dc31ba7"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG-ViBuiQ1lv"
      },
      "source": [
        "<p><h3><b><font color = 'DarkBlue'> Loading the MNIST dataset in Keras </font></b></h3></p>\r\n",
        "\r\n",
        "The MNIST dataset comes preloaded in Keras, in the form of a set of four Numpy\r\n",
        "arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKsHYywNHWPM"
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWUKlh1bHWT4",
        "outputId": "bf01ff10-9b48-40cc-8ea2-5ae3a3086485"
      },
      "source": [
        "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()  # similar xtrain, ytrain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdkaeCVgROBB"
      },
      "source": [
        "<p><b>train_images and train_labels form the training set, the data that the model will learn from. The model will then be tested on the test set, test_images and test_labels.</b></p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRPvGgBwHWYF",
        "outputId": "b9e8d11c-7667-4c4c-8ae3-dbb6a70d2acc"
      },
      "source": [
        "train_images.shape  # 60000 images each 28 by 28 pixel which would be converted to 28*28=764"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CGzqvc3HWcO",
        "outputId": "b21a6fd0-7bd2-4782-e45e-8b8304b3f8d9"
      },
      "source": [
        "train_labels  # target array "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnTQHWJuHWj9",
        "outputId": "5dd940e0-bf62-49cc-f054-0ad345ebd070"
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq021oBqt759",
        "outputId": "cd74510f-f295-40fa-c2ac-71c7d6400893"
      },
      "source": [
        "train_images[:5,:,:]  # to see 1st five images normal indexing in numpy arrays"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]],\n",
              "\n",
              "       [[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xvhlrwJRTP0"
      },
      "source": [
        "<p><h3><font color= 'DarkBlue'><b> Visualizing first four samples in Train dataset </b></font></h3></p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahOVQ9LuHWpL",
        "outputId": "ebe480ef-b154-4067-9614-b665aeadb286"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "train_images[0,:,:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "9VVibp17HWuA",
        "outputId": "13ab5f5e-9e98-4515-ca48-c8b67c936dd4"
      },
      "source": [
        "plt.subplot(2,2,1)\r\n",
        "plt.imshow(train_images[0], cmap='gray') \r\n",
        "plt.subplot(2,2,2)    # creating subplots,with 2 rows and 2 columns(2,2) in subplot1 we create 0th image, subplot2 1st image, subplot3 2nd image.\r\n",
        "plt.imshow(train_images[1], cmap='gray')\r\n",
        "plt.subplot(2,2,3)\r\n",
        "plt.imshow(train_images[2], cmap='gray')\r\n",
        "plt.subplot(2,2,4)\r\n",
        "plt.imshow(train_images[3], cmap='gray');\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMvDN0VfRd35"
      },
      "source": [
        "<p><h3><b><font color = 'DarkBlue'> Preparing the image data ie creating feature matrix</font></b></h3></p>\r\n",
        "\r\n",
        "The training dataset is structured as a 3-dimensional array of instance, image width and image height. For a multi-layer perceptron model we must reduce the images down into a vector of pixels. In this case the 28×28 sized images will be 784 pixel input values.\r\n",
        "\r\n",
        "Before training, we’ll preprocess the data by reshaping it into the shape the network expects and scaling it so that all values are in the [0, 1] interval. Previously, our training\r\n",
        "images, for instance, were stored in an array of shape (60000, 28, 28) of type uint8 with values in the [0, 255] interval. We transform it into a float32 array of\r\n",
        "shape (60000, 28 * 28) with values between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YbClDd2HW6l",
        "outputId": "6d7b1096-f6e4-482b-b549-8c562ee24784"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaptU7uzHW-f",
        "outputId": "677c226f-df16-4f97-bc56-78cf63ccf338"
      },
      "source": [
        "train_images[1,10:20,10:20]  # first image 10:20 row pixels and 10 to 20 column pixels. output is the pixel values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[238, 252, 252, 179,  12,  75, 121,  21,   0,   0],\n",
              "       [253, 233, 208,  84,   0,   0,   0,   0,   0,   0],\n",
              "       [240,  71,  19,  28,   0,   0,   0,   0,   0,   0],\n",
              "       [ 63,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   7, 135],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   7, 131, 252],\n",
              "       [  0,   0,   0,   0,   0,   0,  48, 165, 252, 173],\n",
              "       [  0,   0,   0,   0,   0, 114, 238, 253, 162,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6QDQkKq3IM3"
      },
      "source": [
        "https://www.w3schools.com/colors/colors_rgb.asp. Color intensity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sItlXz68HXCM"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))   # converting 3 dimensional matrix to 2 dimensional matrix 60000 rows and 784 columns\r\n",
        "train_images = train_images.astype('float32') / 255   #normalizing 255 is the intensity value of color 0-255 are the values acts as std scaler\r\n",
        "test_images = test_images.reshape((10000, 28 * 28)) \r\n",
        "test_images = test_images.astype('float32') / 255  #here we do not have color images hence we divide it by 255\r\n",
        " #mandatory data preprocessing step for images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNqM_L9UHXF5",
        "outputId": "5b1da511-2b12-43ca-c16a-f6d9d78ed583"
      },
      "source": [
        "train_images.ndim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEuQ6uqMHXJb",
        "outputId": "c864bf58-7b1b-4129-fb34-8bca2d7a03aa"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBYFZsoFHXM5",
        "outputId": "464f6bfa-1571-444e-b401-0d1492f3cdf1"
      },
      "source": [
        "train_images[1,10:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-HbTpOH4mqw"
      },
      "source": [
        "<p><h3><b><font color = 'DarkBlue'> Preparing the labels </font></b></h3></p>\r\n",
        "\r\n",
        "The output variable is an integer from 0 to 9. This is a multi-class classification problem. As such, it is good practice to use a one hot encoding of the class values, transforming the vector of class integers into a binary matrix. We use to_categorical() to encode the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWFbArIjHXQb",
        "outputId": "dcba779a-c78c-4f2d-9311-0acf26fa8e0b"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6G8BtI7HXUH"
      },
      "source": [
        "from keras.utils import to_categorical    # Creates dummies as get_dummies here it is t0_categorical methods which would convert train_labels from i dimensional to 2 dimensional\r\n",
        "train_labels=to_categorical(train_labels) # where ever true labels are there the value would be 1 else 0\r\n",
        "test_labels=to_categorical(test_labels)    #mandatory data preprocessing step for images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Wvlmw9HXXT",
        "outputId": "f9524bc7-2609-4e81-d579-8acbeb8ae883"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-Hv4STxHXa-",
        "outputId": "a3ceebfd-49f5-4ec6-d33a-435c359c27e8"
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXOmnlGW5-la"
      },
      "source": [
        "<p><h3><b><font color = 'DarkBlue'> Network Architecture </font></b></h3></p>\r\n",
        "\r\n",
        "# ***1. Building a Sequential Model ***\r\n",
        "  We can create a deep learning sequential model with two layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSqzdfDWHXeX"
      },
      "source": [
        "from keras import models\r\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isikFViO7ZPY"
      },
      "source": [
        "<p> We are creating a simple model with one hidden layer with 300 number of neurons. A rectifier activation function is used for the neurons in the hidden layer. \r\n",
        "A softmax activation function is used on the output layer to turn the outputs into probability-like values and allow one class of the 10 to be selected as the model’s output prediction.`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABuMx001SoHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6cbaa2-31e3-43cc-ca71-8c6dfe7fe872"
      },
      "source": [
        "network = keras.models.Sequential() # creating a instance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-58d0dd34fbce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# creating a instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMogpGvuSoSd"
      },
      "source": [
        "network.add(keras.layers.Dense(300, activation='relu', input_shape=(784,)))\r\n",
        "# .add is used to add layer.add first layer, dense layer (hidden layer)with 300 neurons, relu as activation function and input shape as 784. number of neurons does not affect the model just there will difference in the calculations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yllfjp3GSoc5"
      },
      "source": [
        "300*784+300  #300 neurons * 784 features + 300 bias  # number of parameters in the 1st hidden layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixAbJNzcSohh"
      },
      "source": [
        "network.summary()  #summary is a method which will tell us the network architecture, here one layer with 300 neurons and 235500 parameters\r\n",
        "#trainable parameters are those which will be updated and calculated during backward and forward pass. nontrainable parameters do not get affected during fit method"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxb5Y2rUDRWP"
      },
      "source": [
        " In softmax number of neurons will be equal to number of classes. For binary classification we will have only one neuron and we will use sigmoid as activation function.If its not binary usually it would be soft max."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wErRnuSzSom2"
      },
      "source": [
        "network.add(keras.layers.Dense(10, activation='softmax')) # in softmax number of neurons will be equal to number of class\r\n",
        "#will add an other output layer. since there are 10 classes we add 10 neurons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBUsxal-Sovm"
      },
      "source": [
        "network.summary()  # 2 layers first with 300 neurons and 235500 parameters and 2nd output layer with 10 neurons and 3010 parameters(300*10)+10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsaZha4nSo0H"
      },
      "source": [
        "len(network.layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe6e2EprSo4c"
      },
      "source": [
        "network.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYSn3VquSo83"
      },
      "source": [
        "#network.pop()   # to remove last layer from the model use pop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRsQzOKXHXhb"
      },
      "source": [
        "weights = network.get_weights()\r\n",
        "#will give the weights of both the layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gaJ4p_3HXkk"
      },
      "source": [
        "type(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toc0o_zjHXnq"
      },
      "source": [
        "weights[0].shape,weights[1].shape,weights[2].shape,weights[3].shape\r\n",
        "# weight 0 is the weight of the hidden layer, shape.weights 1 is the bias for the hidden layer, shape wts2 is the wt of the output layer and weight 3 is the bias for the output layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVtLuc0QHXqx"
      },
      "source": [
        "weights[2] \r\n",
        "# randomly initialized weights for each neuron for each layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l1cHG0PHXt7"
      },
      "source": [
        "weights[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSVcG3XKHXxg"
      },
      "source": [
        "#keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5OZgt-5GTCc"
      },
      "source": [
        "<p><h3><b><font color = 'DarkBlue'> Compilation Step</font></b></h3></p>\r\n",
        "\r\n",
        "We will call compile() to specify the loss function. As our targets are one-hot vectors we would use 'categorical_crossentropy' loss function. \r\n",
        "\r\n",
        "The optimizer we are using is simple Stochastic Gradient Descent 'sgd' which is used to learn the weights. \r\n",
        "\r\n",
        "As this is a classifier model we use 'accuracy' as the metrics for evaluation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSE7KflZGQTY"
      },
      "source": [
        "network.compile(optimizer= keras.optimizers.SGD(learning_rate=0.01),\r\n",
        "loss='categorical_crossentropy',\r\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc7YR2fEGQXb"
      },
      "source": [
        "network.compile(optimizer= 'SGD',\r\n",
        "loss='categorical_crossentropy',\r\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjIXv0wOGiaU"
      },
      "source": [
        "<p><h3><b><font color = 'DarkBlue'> Fit the model with train data  </font></b></h3></p>\r\n",
        "\r\n",
        "We call fit() to train out model.\r\n",
        "\r\n",
        "It takes input features(train_images) and the target classes (train_labels) as well as the number of epochs to train. \r\n",
        "\r\n",
        "The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset.\r\n",
        "\r\n",
        "One epoch means that each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCWlzC-JGQaZ"
      },
      "source": [
        "60000/512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzmgcNY5GQdU"
      },
      "source": [
        "test_images.shape,train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmQ8yfJL441F"
      },
      "source": [
        "history = network.fit(train_images, train_labels,epochs=10,batch_size=512,validation_data=(test_images,test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM2uYfG7GQhL"
      },
      "source": [
        "history.validation_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY2FQCrLG36d"
      },
      "source": [
        "<p><b>Two quantities are displayed during training: the loss of the network over the training data, and the accuracy of the network over the training data.</b></p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pasXbHlfGQke"
      },
      "source": [
        "y_proba = network.predict(test_images)    # predict() estimates one probablity per class from 0 to 9\r\n",
        "y_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh1VWi2MGQn9"
      },
      "source": [
        "y_proba[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIDRd42HGQre"
      },
      "source": [
        "y_proba.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljOPqo36GQvf"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69qnBcZ7GQyW"
      },
      "source": [
        "test_1 = test_images[0,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_4z2rj4GQ1r"
      },
      "source": [
        "test_1 = test_1.reshape([28,28])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtFsUBEqGQ45"
      },
      "source": [
        "plt.imshow(test_1,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3ylwtChGRBo"
      },
      "source": [
        "y_pred = network.predict_classes(test_images)   # predict_classes() outputs the class with highest estimated probability\r\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8A238gbHQnA"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJC6Dc2HHQqe"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVYILf5wHQv8"
      },
      "source": [
        "y_actual = np.argmax(test_labels,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6F3fBlyHQ10"
      },
      "source": [
        "y_actual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUlmV2BqHQ5e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfKPr5OkHQ8m"
      },
      "source": [
        "confusion_matrix(y_actual,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5IFZ5fKHi15"
      },
      "source": [
        "<p><h3><b><font color = 'DarkBlue'> Evaluate the model  </font></b></h3></p>\r\n",
        "\r\n",
        "check the performance of model on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Yx4pF5HRAU"
      },
      "source": [
        "test_loss, test_acc = network.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mso-HIDHRDY"
      },
      "source": [
        "print('test_acc:', test_acc)\r\n",
        "print('test_loss :', test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRt4Kc6I21RC"
      },
      "source": [
        "#plot accuracy And Loss graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oybpiUj2HRGq"
      },
      "source": [
        "plt.figure()\r\n",
        "plt.plot(history.history['loss'], '-g')\r\n",
        "plt.plot(history.history['val_loss'], '-b')\r\n",
        "plt.legend(['Train','Validation'])\r\n",
        "plt.title('Train Loss vs Validation Loss')\r\n",
        "plt.figure()\r\n",
        "plt.plot(history.history['accuracy'], '-g')\r\n",
        "plt.plot(history.history['val_accuracy'], '-b')\r\n",
        "plt.legend(['Train','Validation'])\r\n",
        "plt.title('Train Accuracy vs Validation Accuracy')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VeNLqRaHRJq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY4DN3QRHRQW"
      },
      "source": [
        "train_X=train_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1uBwahOHRUv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoeF-On9GRF7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3SdV9rQHX1B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhQSrZFbHX4P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0nf447uHX7k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drhVtclSHX-x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}